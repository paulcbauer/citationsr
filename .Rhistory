if(is.null(foo[z,y][[1]])){foo[z,y][[1]] <- NA}
}}
# save metadatatables in data folder
save(foo, file = paste("./", folder, "_metadata.RData", sep=""))
# RENAME DOCS USING METADATA
# rename_docs(folder = folder)
# IDENTIFY STUDY IN DOCS
# identify_study_doc(study.title = study.title,
#                  folder = folder)
# CLEAN TEXT FILES BEFORE CASE EXTRACTION
#delete_refs_n_heads(folder = folder)
#clean_text(folder = folder)
# EXTRACT CITATION CASES
#extract_citation_cases(folder = folder,
#                         authorname = authors,
#                         studyyear = year)
}
for (i in 5){
# SPECIFY ARGUMENT FOR SINGLE FUNCTIONS
folder <- publicationdata[i,1]
study.title <- publicationdata[i,2]
authors <- publicationdata[i,3]
year <- publicationdata[i,4]
# TEXT EXTRACTION
# extract_text(folder = folder)
# GETTING METADATA
files <- list.files(folder, pattern = "txt$", full.names = T)
foo <- plyr::adply(files[1:length(files)], .margins = 1, .fun = get_metadata_doc,
.progress = "text")
# Replace NULL values in metadata tables
for(z in 1:nrow(foo)){for(y in 1:length(foo)){
if(is.null(foo[z,y][[1]])){foo[z,y][[1]] <- NA}
}}
# save metadatatables in data folder
save(foo, file = paste("./", folder, "_metadata.RData", sep=""))
# RENAME DOCS USING METADATA
# rename_docs(folder = folder)
# IDENTIFY STUDY IN DOCS
# identify_study_doc(study.title = study.title,
#                  folder = folder)
# CLEAN TEXT FILES BEFORE CASE EXTRACTION
#delete_refs_n_heads(folder = folder)
#clean_text(folder = folder)
# EXTRACT CITATION CASES
#extract_citation_cases(folder = folder,
#                         authorname = authors,
#                         studyyear = year)
}
for (i in 6){
# SPECIFY ARGUMENT FOR SINGLE FUNCTIONS
folder <- publicationdata[i,1]
study.title <- publicationdata[i,2]
authors <- publicationdata[i,3]
year <- publicationdata[i,4]
# TEXT EXTRACTION
# extract_text(folder = folder)
# GETTING METADATA
files <- list.files(folder, pattern = "txt$", full.names = T)
foo <- plyr::adply(files[1:length(files)], .margins = 1, .fun = get_metadata_doc,
.progress = "text")
# Replace NULL values in metadata tables
for(z in 1:nrow(foo)){for(y in 1:length(foo)){
if(is.null(foo[z,y][[1]])){foo[z,y][[1]] <- NA}
}}
# save metadatatables in data folder
save(foo, file = paste("./", folder, "_metadata.RData", sep=""))
# RENAME DOCS USING METADATA
# rename_docs(folder = folder)
# IDENTIFY STUDY IN DOCS
# identify_study_doc(study.title = study.title,
#                  folder = folder)
# CLEAN TEXT FILES BEFORE CASE EXTRACTION
#delete_refs_n_heads(folder = folder)
#clean_text(folder = folder)
# EXTRACT CITATION CASES
#extract_citation_cases(folder = folder,
#                         authorname = authors,
#                         studyyear = year)
}
# Loop across rows of 'publicationdata'
for (i in 6){
# SPECIFY ARGUMENT FOR SINGLE FUNCTIONS
folder <- publicationdata[i,1]
study.title <- publicationdata[i,2]
authors <- publicationdata[i,3]
year <- publicationdata[i,4]
# TEXT EXTRACTION
# extract_text(folder = folder)
# GETTING METADATA
# files <- list.files(folder, pattern = "txt$", full.names = T)
# foo <- plyr::adply(files[1:length(files)], .margins = 1, .fun = get_metadata_doc,
#                  .progress = "text")
# Replace NULL values in metadata tables
# for(z in 1:nrow(foo)){for(y in 1:length(foo)){
#    if(is.null(foo[z,y][[1]])){foo[z,y][[1]] <- NA}
#  }}
# save metadatatables in data folder
# save(foo, file = paste("./", folder, "_metadata.RData", sep=""))
# RENAME DOCS USING METADATA
rename_docs(folder = folder)
# IDENTIFY STUDY IN DOCS
# identify_study_doc(study.title = study.title,
#                  folder = folder)
# CLEAN TEXT FILES BEFORE CASE EXTRACTION
#delete_refs_n_heads(folder = folder)
#clean_text(folder = folder)
# EXTRACT CITATION CASES
#extract_citation_cases(folder = folder,
#                         authorname = authors,
#                         studyyear = year)
}
for (i in 6){
# SPECIFY ARGUMENT FOR SINGLE FUNCTIONS
folder <- publicationdata[i,1]
study.title <- publicationdata[i,2]
authors <- publicationdata[i,3]
year <- publicationdata[i,4]
# TEXT EXTRACTION
# extract_text(folder = folder)
# GETTING METADATA
# files <- list.files(folder, pattern = "txt$", full.names = T)
# foo <- plyr::adply(files[1:length(files)], .margins = 1, .fun = get_metadata_doc,
#                  .progress = "text")
# Replace NULL values in metadata tables
# for(z in 1:nrow(foo)){for(y in 1:length(foo)){
#    if(is.null(foo[z,y][[1]])){foo[z,y][[1]] <- NA}
#  }}
# save metadatatables in data folder
# save(foo, file = paste("./", folder, "_metadata.RData", sep=""))
# RENAME DOCS USING METADATA
# rename_docs(folder = folder)
# IDENTIFY STUDY IN DOCS
# identify_study_doc(study.title = study.title,
#                  folder = folder)
# CLEAN TEXT FILES BEFORE CASE EXTRACTION
delete_refs_n_heads(folder = folder)
clean_text(folder = folder)
# EXTRACT CITATION CASES
#extract_citation_cases(folder = folder,
#                         authorname = authors,
#                         studyyear = year)
}
for (i in 1:5){
# SPECIFY ARGUMENT FOR SINGLE FUNCTIONS
folder <- publicationdata[i,1]
study.title <- publicationdata[i,2]
authors <- publicationdata[i,3]
year <- publicationdata[i,4]
# TEXT EXTRACTION
# extract_text(folder = folder)
# GETTING METADATA
# files <- list.files(folder, pattern = "txt$", full.names = T)
# foo <- plyr::adply(files[1:length(files)], .margins = 1, .fun = get_metadata_doc,
#                  .progress = "text")
# Replace NULL values in metadata tables
# for(z in 1:nrow(foo)){for(y in 1:length(foo)){
#    if(is.null(foo[z,y][[1]])){foo[z,y][[1]] <- NA}
#  }}
# save metadatatables in data folder
# save(foo, file = paste("./", folder, "_metadata.RData", sep=""))
# RENAME DOCS USING METADATA
# rename_docs(folder = folder)
# IDENTIFY STUDY IN DOCS
# identify_study_doc(study.title = study.title,
#                  folder = folder)
# CLEAN TEXT FILES BEFORE CASE EXTRACTION
delete_refs_n_heads(folder = folder)
clean_text(folder = folder)
# EXTRACT CITATION CASES
#extract_citation_cases(folder = folder,
#                         authorname = authors,
#                         studyyear = year)
}
for (i in 1:6){
# SPECIFY ARGUMENT FOR SINGLE FUNCTIONS
folder <- publicationdata[i,1]
study.title <- publicationdata[i,2]
authors <- publicationdata[i,3]
year <- publicationdata[i,4]
# TEXT EXTRACTION
# extract_text(folder = folder)
# GETTING METADATA
# files <- list.files(folder, pattern = "txt$", full.names = T)
# foo <- plyr::adply(files[1:length(files)], .margins = 1, .fun = get_metadata_doc,
#                  .progress = "text")
# Replace NULL values in metadata tables
# for(z in 1:nrow(foo)){for(y in 1:length(foo)){
#    if(is.null(foo[z,y][[1]])){foo[z,y][[1]] <- NA}
#  }}
# save metadatatables in data folder
# save(foo, file = paste("./", folder, "_metadata.RData", sep=""))
# RENAME DOCS USING METADATA
rename_docs(folder = folder)
# IDENTIFY STUDY IN DOCS
# identify_study_doc(study.title = study.title,
#                  folder = folder)
# CLEAN TEXT FILES BEFORE CASE EXTRACTION
# delete_refs_n_heads(folder = folder)
# clean_text(folder = folder)
# EXTRACT CITATION CASES
#extract_citation_cases(folder = folder,
#                         authorname = authors,
#                         studyyear = year)
}
i <- 3
folder <- publicationdata[i,1]
study.title <- publicationdata[i,2]
authors <- publicationdata[i,3]
year <- publicationdata[i,4]
folder
study.title
authors
year
for (i in 3){
# SPECIFY ARGUMENT FOR SINGLE FUNCTIONS
folder <- publicationdata[i,1]
study.title <- publicationdata[i,2]
authors <- publicationdata[i,3]
year <- publicationdata[i,4]
# TEXT EXTRACTION
extract_text(folder = folder)
# GETTING METADATA
# files <- list.files(folder, pattern = "txt$", full.names = T)
# foo <- plyr::adply(files[1:length(files)], .margins = 1, .fun = get_metadata_doc,
#                  .progress = "text")
# Replace NULL values in metadata tables
# for(z in 1:nrow(foo)){for(y in 1:length(foo)){
#    if(is.null(foo[z,y][[1]])){foo[z,y][[1]] <- NA}
#  }}
# save metadatatables in data folder
# save(foo, file = paste("./", folder, "_metadata.RData", sep=""))
# RENAME DOCS USING METADATA
rename_docs(folder = folder)
# IDENTIFY STUDY IN DOCS
# identify_study_doc(study.title = study.title,
#                  folder = folder)
# CLEAN TEXT FILES BEFORE CASE EXTRACTION
delete_refs_n_heads(folder = folder)
clean_text(folder = folder)
# EXTRACT CITATION CASES
extract_citation_cases(folder = folder,
authorname = authors,
studyyear = year)
}
for (i in 4){
# SPECIFY ARGUMENT FOR SINGLE FUNCTIONS
folder <- publicationdata[i,1]
study.title <- publicationdata[i,2]
authors <- publicationdata[i,3]
year <- publicationdata[i,4]
# TEXT EXTRACTION
extract_text(folder = folder)
# GETTING METADATA
# files <- list.files(folder, pattern = "txt$", full.names = T)
# foo <- plyr::adply(files[1:length(files)], .margins = 1, .fun = get_metadata_doc,
#                  .progress = "text")
# Replace NULL values in metadata tables
# for(z in 1:nrow(foo)){for(y in 1:length(foo)){
#    if(is.null(foo[z,y][[1]])){foo[z,y][[1]] <- NA}
#  }}
# save metadatatables in data folder
# save(foo, file = paste("./", folder, "_metadata.RData", sep=""))
# RENAME DOCS USING METADATA
rename_docs(folder = folder)
# IDENTIFY STUDY IN DOCS
# identify_study_doc(study.title = study.title,
#                  folder = folder)
# CLEAN TEXT FILES BEFORE CASE EXTRACTION
delete_refs_n_heads(folder = folder)
clean_text(folder = folder)
# EXTRACT CITATION CASES
extract_citation_cases(folder = folder,
authorname = authors,
studyyear = year)
}
for (i in 5){
# SPECIFY ARGUMENT FOR SINGLE FUNCTIONS
folder <- publicationdata[i,1]
study.title <- publicationdata[i,2]
authors <- publicationdata[i,3]
year <- publicationdata[i,4]
# TEXT EXTRACTION
extract_text(folder = folder)
# GETTING METADATA
# files <- list.files(folder, pattern = "txt$", full.names = T)
# foo <- plyr::adply(files[1:length(files)], .margins = 1, .fun = get_metadata_doc,
#                  .progress = "text")
# Replace NULL values in metadata tables
# for(z in 1:nrow(foo)){for(y in 1:length(foo)){
#    if(is.null(foo[z,y][[1]])){foo[z,y][[1]] <- NA}
#  }}
# save metadatatables in data folder
# save(foo, file = paste("./", folder, "_metadata.RData", sep=""))
# RENAME DOCS USING METADATA
rename_docs(folder = folder)
# IDENTIFY STUDY IN DOCS
# identify_study_doc(study.title = study.title,
#                  folder = folder)
# CLEAN TEXT FILES BEFORE CASE EXTRACTION
delete_refs_n_heads(folder = folder)
clean_text(folder = folder)
# EXTRACT CITATION CASES
extract_citation_cases(folder = folder,
authorname = authors,
studyyear = year)
}
for (i in 6){
# SPECIFY ARGUMENT FOR SINGLE FUNCTIONS
folder <- publicationdata[i,1]
study.title <- publicationdata[i,2]
authors <- publicationdata[i,3]
year <- publicationdata[i,4]
# TEXT EXTRACTION
extract_text(folder = folder)
# GETTING METADATA
# files <- list.files(folder, pattern = "txt$", full.names = T)
# foo <- plyr::adply(files[1:length(files)], .margins = 1, .fun = get_metadata_doc,
#                  .progress = "text")
# Replace NULL values in metadata tables
# for(z in 1:nrow(foo)){for(y in 1:length(foo)){
#    if(is.null(foo[z,y][[1]])){foo[z,y][[1]] <- NA}
#  }}
# save metadatatables in data folder
# save(foo, file = paste("./", folder, "_metadata.RData", sep=""))
# RENAME DOCS USING METADATA
rename_docs(folder = folder)
# IDENTIFY STUDY IN DOCS
# identify_study_doc(study.title = study.title,
#                  folder = folder)
# CLEAN TEXT FILES BEFORE CASE EXTRACTION
delete_refs_n_heads(folder = folder)
clean_text(folder = folder)
# EXTRACT CITATION CASES
extract_citation_cases(folder = folder,
authorname = authors,
studyyear = year)
}
library(citations)
library(citations)
getwd()
setwd("C:/Users/pbauer/Google Drive/Packages/citations/data")
setwd("C:/Users/pbauer/Google Drive/Research/2016_Quality_of_citations/data")
dir()
x <- read.csv("Acemoglu 2001_citation_cases.csv" , stringsAsFactors=F, row.names=NULL, fileEncoding="latin1")
x <- read.csv("Acemoglu 2001_citation_cases.csv" , stringsAsFactors=F, row.names=NULL, fileEncoding="latin1", sep=",")
x <- read.table("Acemoglu 2001_citation_cases.csv" , stringsAsFactors=F, row.names=NULL, fileEncoding="latin1", sep=",")
x <- read.table("Acemoglu 2001_citation_cases.csv" , stringsAsFactors=F, row.names=NULL, sep=",")
stargazer(x[1:10,])
library(stargazer)
stargazer(x[1:10,])
stargazer(x)
?stargazer
stargazer(x, summary=F)
stargazer(x[1:10,], summary=F)
stargazer(x[1:20,], summary=F)
stargazer(x[1:20,], summary=F)
stargazer(x[1:15,], summary=F)
View(x)
names(x)
x <- x[,2:3]
stargazer(x[1:15,], summary=F)
stargazer(x[1:15,], summary=F, row.names=F)
579/1957
round(579/1957,2)
round(579/1957,3)
490/1321
1155/1715
499/1139
479/1647
527/1452
library(citations)
getwd()
file <- "~/Google Drive/2016_Quality_of_citations/data/Fearon 2003_citation_cases.csv"
article <- "Fearon and Laitin (2003)"
output <- "fearon_2003"
?analyze_citations
analyze_citations <- function(file, article, output){
require(ggplot2)
require(scales)
require(quanteda)
# precleaning file
text <- scan(file, what="character", sep="\n")
text <- gsub('\\\\"', "''", text)
text <- paste0(text, collapse="\n")
tmp <- tempfile()
writeLines(text, con=tmp)
# reading file and cleaning data
tf <- read.csv(tmp, stringsAsFactors=F, row.names=NULL, fileEncoding="latin1")
# extracting year, deleting citations with empty years
tf$year <- as.numeric(gsub('.*([0-9]{4}).*', tf$document, repl='\\1'))
message("Warning: ", sum(is.na(tf$year)), " citation cases with missing year will be excluded from analysis.")
todelete <- which(is.na(tf$year))
message("Warning: ", sum(duplicated(tf$citation.case)), " duplicated citation cases will be excluded from analysis.")
todelete <- c(todelete, which(duplicated(tf$citation.case)))
message("Warning: ", sum(nchar(tf$citation.case)>1000), " citation cases longer than 1000 characters will be excluded from analysis.")
todelete <- unique(c(todelete, which(nchar(tf$citation.case)>1000)))
# exporting
write.csv(tf[todelete,], file=paste0(output, '/parsing-errors.csv'), row.names=FALSE)
tf <- tf[-todelete,]
message("A total of ", nrow(tf), " citation cases will be included in the analysis.")
# generating histogram with times cited within document
x <- table(tf$document)
range.x <- range(x)
breaks <- c(range.x[1]:range.x[2]-0.5, range.x[2]+0.5)
seq.x <- seq(range.x[1], range.x[2], 1)
f1 <- paste0(output, '/01-times-cited-within-document.pdf')
pdf(f1, height=4, width=6)
par (mar=c(3,3,2,1), mgp=c(2,.7,0), tck=-.025)
hist(x, xlab="N citation cases per document",
main = paste0("Citation cases: ", article), xaxt="n",
breaks=breaks, cex.main=1, ylab="Frequency = N documents")
axis(1,seq.x)
dev.off()
message("File generated: ", f1)
# generating histograms for co-citations
tf$citation_counts <- stringr::str_count(tf$citation.case, "(19|20)[0-9]{2}")
x <- tf$citation_counts
# table(x)
range.x <- range(x)
breaks <- c(range.x[1]:range.x[2]-0.5, range.x[2]+0.5)
seq.x <- c(seq(range.x[1], range.x[2], 1))
f2 <- paste0(output, '/02-co-citations-in-citation-case.pdf')
pdf(f2, height=4, width=6)
par (mar=c(3,3,2,1), mgp=c(2,.7,0), tck=-.025)
hist(x, xlab="N references within citation case",
main = paste0("Citation cases: ", article), xaxt="n", breaks = breaks,  cex.main=1, ylab="Frequency = N citation cases")
axis(1,seq.x)
dev.off()
message("File generated: ", f2)
# generating average number of references per citation over time
tf_group <- aggregate(tf$citation_counts, by=list(year=tf$year), FUN=mean, na.rm=TRUE)
p <- ggplot(tf_group, aes(x=as.numeric(year), y=x))
pq <- p + geom_point() + geom_line() + theme_minimal() +
theme(axis.title.x=element_blank()) +
scale_y_continuous("Average number of references in citation case") +
ggtitle(paste0("Citation cases: ", article))
f3 <- paste0(output, '/03-co-citations-over-time.pdf')
ggsave(pq, file=f3, height=4, width=6)
message("File generated: ", f3)
# figure with positive signals
signal.words <- paste0("follow|recommend|validate|suggest|accordance|advice|demonstrate",
"|confirm|support|in line with|based")
tf$signal_positive <- grepl(signal.words, tf$citation.case)
tf_group <- aggregate(tf$signal_positive, by=list(year=tf$year), FUN=mean, na.rm=TRUE)
p <- ggplot(tf_group, aes(x=as.numeric(year), y=x))
pq <- p + geom_point() + geom_line() + theme_minimal() +
theme(axis.title.x=element_blank()) +
scale_y_continuous("Proportion of citations with `positive' signal",
label=percent) + ggtitle(paste0("Citation cases: ", article))
f4 <- paste0(output, '/04-citations-with-positive-signal.pdf')
ggsave(pq, file=f4, height=4, width=6)
message("File generated: ", f4)
# text cleaning
authors <- tokenize(toLower(c(tf$document, article)), removePunct=T, removeNumbers=T)
authors <- unique(unlist(authors))
# tokenizing
tokens <- tokenize(toLower(tf$citation.case), removePunct=T, removeNumbers=T)
# removing stopwords, author names, and other frequent words
tokens <- removeFeatures(tokens,
c(stopwords("english"), "other", "others", "see", "also", "u", authors))
# stemming?
#tokens <- lapply(tokens, wordstem)
# creating n-grams
ngrams <- lapply(tokens, ngrams, 1:3)
# putting it all back together...
ngrams <- unlist(lapply(ngrams, paste, collapse=" "))
# constructing the DFM
cit <- corpus(ngrams)
docnames(cit) <- paste0(1:nrow(tf), '_', tf$document)
# summary(cit)
citmat <- dfm(cit)
# word cloud
f5 <- paste0(output, '/05-citations-word-cloud.pdf')
pdf(f5, height=4, width=4)
par (mar=c(0,0,0,0))
plot(citmat, rot.per=0, scale=c(3, .3), max.words=80)
dev.off()
message("File generated: ", f5)
# sentiment analysis
dict <- qdapDictionaries::key.pol
mydict <- dictionary(list(negative = dict$x[dict$y==-1],
postive = dict$x[dict$y==1]))
myDfm <- dfm(cit, dictionary = mydict)
tf$neg <- as.numeric(myDfm[,1])
tf$pos <- as.numeric(myDfm[,2])
tf$score <- (tf$pos - tf$neg)
tf_group <- aggregate(tf$score, by=list(year=tf$year), FUN=mean, na.rm=TRUE)
p <- ggplot(tf_group, aes(x=as.numeric(year), y=x))
pq <- p + geom_point() + geom_line() + theme_minimal() +
theme(axis.title.x=element_blank()) +
scale_y_continuous("Average sentiment in citations") +
ggtitle(paste0("Citation cases: ", article))
f6 <- paste0(output, '/06-sentiment-over-time.pdf')
ggsave(pq, file=f6, height=4, width=6)
message("File generated: ", f6)
}
analyze_citations(file, article, output)
file <- "C:/Users/pbauer/Google Drive/2016_Quality_of_citations/data/Fearon 2003_citation_cases.csv"
analyze_citations(file, article, output)
file <- "C:/Users/pbauer/Google Drive/2016_Quality_of_citations/data/Fearon 2003_citation_cases.csv"
text <- scan(file, what="character", sep="\n")
file <- "C:/Users/pbauer/Google Drive/Research/2016_Quality_of_citations/data/Fearon 2003_citation_cases.csv"
analyze_citations(file, article, output)
require(ggplot2)
require(scales)
require(quanteda)
text <- scan(file, what="character", sep="\n")
text <- gsub('\\\\"', "''", text)
text <- paste0(text, collapse="\n")
tmp <- tempfile()
writeLines(text, con=tmp)
tf <- read.csv(tmp, stringsAsFactors=F, row.names=NULL, fileEncoding="latin1")
