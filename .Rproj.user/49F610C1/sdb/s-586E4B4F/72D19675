{
    "collab_server" : "",
    "contents" : "#' Identifies meta information within txt documents.\n#'\n#' @param filename Input file; assumed to be txt format..\n#' @param encoding Character encoding scheme of input txt file. Default is \"utf-8\".\n#' @param lines.import Number of lines that should be imported from the input txt file. Default is 2000.\n#' @param rcrossref Use rcrossref function to identify article meta data via CrossRef API? Default is TRUE. Currently, no useful other ways of identifying metadata are implemented.\n#' @param bibtex Should reference be exported as bibtex? Works only with rcrossref = TRUE. Default is FALSE.\n#' @param vars Which variables should be returned? Specify as character vectors. By default, all available variables are returned.\n#'\n#'\n\n#' @description Takes a single txt file as input. To operate on a vector of txt files, use get_metadata_doc().\n#'\n#' @examples\n#' \\dontrun{\n#'  setwd(\"C:/Users/paul/Google Drive/Research/2016_Quality_of_citations/data\")\n#'  folder <- \"docs\"\n#'  number <- 20 # or do not specify\n#'  get_metadata_doc_nv(folder)\n#'  ...set also other arguments in the funcion....\n#' }\n\n\nget_metadata_doc_nv <- function(folder, number=NULL, encoding = \"UTF-8\", lines.import = 2000, rcrossref = TRUE, bibtex = FALSE, vars = NULL){\n\n  # load packages\n  require(magrittr)\n  require(stringr)\n  require(dplyr)\n\n  # Identify names of PDF files in folder + their path\n  file.names <- dir(paste(\"./\", folder, sep = \"\"), pattern = \".txt\")\n  file.paths <- paste(paste(\"./\", folder,\"/\", sep = \"\"), file.names, sep=\"\")\n\n  # Count number of files in folder\n  n.docs <- length(file.paths)\n\n  # Specify number of documents to assess by setting n.docs\n  if(!is.null(number)){n.docs <- number}\n  if(!is.null(number)&&number>length(file.paths)){n.docs <- length(file.paths)} # if not enough files\n\n\n  # Measure time\n  ptm <- proc.time()\n\n  # Loop over .pdf files one by one (until document nr. \"number\" = n.docs)\n  metadata <- NULL\n  z <- 0\n  for (i in 1:n.docs){  #\n\n  # filename <- file.paths[\"./docs/NA - NA - Autocratic Institutions and Civil Conflict Contagi.txt\"]\n  z <- z + 1\n  print(z)\n\n  filename <- file.paths[i]\n  print(filename)\n  # open file\n  con <- file(filename, encoding = encoding)\n\n  # import text lines; lines.import specifies number of lines\n  x <- readLines(con, warn = F, n = lines.import)\n  close(con) # close connection\n\n  # remove form feed, line feed, carriage returns and empty lines from doc\n  x <- str_replace_all(x, \"[\\r\\n\\f]\" , \"\")\n  x <- str_replace_all(x, \"^[Dd]ownloaded from.+\" , \"\")\n  x <- str_replace_all(x, \"ﬁ\", \"fi\")\n  x <- x[sapply(x, nchar) > 0]\n\n  # generate empty containers\n  doc_name <- basename(filename)\n  doc_size <- file.size(filename)\n  full_line <- NA\n  doi <- NA\n  meta_source <- NA\n  doi_guess <- NA\n  meta_dat <- data.frame(author = NA, title = NA, container.title = NA, volume = NA, issue = NA, created = NA, issued = NA, page = NA, publisher = NA, subject = NA, type = NA, URL = NA, DOI = NA, ISSN = NA, link = NA, reference.count = NA, score = NA, source = NA)\n\n  # identify DOI\n  doi <- stringr::str_extract(x, '\\\\b(10[.][0-9]{4,}(?:[.][0-9]+)*/(?:(?![\"&\\'])\\\\S)+)\\\\b') # taken from http://stackoverflow.com/questions/27910/finding-a-doi-in-a-document-or-page\n  doi <- doi[!is.na(doi)]\n\n  # check if DOI contains non-ASCII characters\n  check_nonascii <- tools::showNonASCII(doi)\n  doi_nonascii <- ifelse(length(check_nonascii) > 0, TRUE, FALSE)\n\n  # if no DOI available, try fetch it from CrossRef via information from first 20 lines\n  # detect frequent lines (headers?)\n  if(length(doi)==0){\n    # significant_lines <- sort(table(x), decreasing = TRUE)[1:3] # header approach\n    # significant_lines_combined <- paste(names(frequent_lines), collapse = \" \")\n    significant_lines_combined <- paste(x[1:20], collapse = \" \") # first 20 lines approach\n    doi <- rcrossref::cr_works(query=significant_lines_combined, limit = 1)$data$DOI\n    doi_guess <- TRUE\n  }\n\n  # if DOI available, query info from CrossRef\n  if(length(doi)!=0 & doi_nonascii == FALSE){\n    # extract lines that contain identifiers of DOI\n    doi <- stringr::str_replace(doi, \"^DOI |^DOI: |DOI:|^doi |^doi: |doi:|http://dx\\\\.doi\\\\.org/\", \"\")\n    doi <- stringr::str_replace(doi, \"_supp$|\\\\.supp$\", \"\")\n    # take the first one\n    doi <- doi[1]\n    if (rcrossref == TRUE) {\n    # query crossref with DOI\n    if(bibtex == TRUE) {\n      crossref_bibtex <- rcrossref::cr_cn(dois = doi, format = \"bibtex\", style = \"apa\")\n      write(crossref_bibtex, paste0(filename, \".bib\"))\n    }\n    crossref_df <- try(rcrossref::cr_works(dois = doi) %>% .$data %>% dplyr::select(matches(\"^author$|^title$|^container.title$|^volume$|^issue$|^created$|^issued$|^page$|^publisher$|^subject$|^type$|^URL$|^DOI$|^ISSN$|^reference.count$|^score$|^source$\")))\n      if (class(crossref_df) != \"try-error\") {   # error handling if call caused an error\n        meta_dat <- crossref_df\n    }\n    meta_source <- \"CrossRef\"\n    }\n  }\n\n  # add empty variables if necessary\n  if (!(\"author\" %in% colnames(meta_dat))) { meta_dat$author <- NA }\n  if (!(\"title\" %in% colnames(meta_dat))) { meta_dat$title <- NA }\n  if (!(\"container.title\" %in% colnames(meta_dat))) { meta_dat$container.title <- NA }\n  if (!(\"volume\" %in% colnames(meta_dat))) { meta_dat$volume <- NA }\n  if (!(\"issue\" %in% colnames(meta_dat))) { meta_dat$issue <- NA }\n  if (!(\"created\" %in% colnames(meta_dat))) { meta_dat$created <- NA }\n  if (!(\"issued\" %in% colnames(meta_dat))) { meta_dat$issued <- NA }\n  if (!(\"page\" %in% colnames(meta_dat))) { meta_dat$page <- NA }\n  if (!(\"publisher\" %in% colnames(meta_dat))) { meta_dat$publisher <- NA }\n  if (!(\"subject\" %in% colnames(meta_dat))) { meta_dat$subject <- NA }\n  if (!(\"type\" %in% colnames(meta_dat))) { meta_dat$type <- NA }\n  if (!(\"URL\" %in% colnames(meta_dat))) { meta_dat$URL <- NA }\n  if (!(\"DOI\" %in% colnames(meta_dat))) { meta_dat$DOI <- NA }\n  if (!(\"ISSN\" %in% colnames(meta_dat))) { meta_dat$ISSN <- NA }\n  if (!(\"reference.count\" %in% colnames(meta_dat))) { meta_dat$reference.count <- NA }\n  if (!(\"score\" %in% colnames(meta_dat))) { meta_dat$score <- NA }\n  if (!(\"source\" %in% colnames(meta_dat))) { meta_dat$source <- NA }\n\n  # attach additional information\n  meta_dat$meta_source <- meta_source\n  meta_dat$doc_name <- doc_name\n  meta_dat$doc_size <- doc_size\n  meta_dat$doi_guess <- doi_guess\n\n  # clean variables\n  meta_dat$journal <- meta_dat$container.title\n  meta_dat$date1 <- meta_dat$created\n  meta_dat$date2 <- meta_dat$issued\n  meta_dat$doc_year <- meta_dat$doc_name %>% str_extract(\"[[:digit:]]{4}\")\n  meta_dat$doc_author <- meta_dat$doc_name %>% str_extract(\"^[[:alpha:]- .]+([[:digit:]]{4}){1}\") %>% str_replace(\"[[:digit:]]{4}\", \"\")\n\n  # clean journal variable\n  journals_num <- meta_dat$journal %>% str_split(\",\") %>% unlist() %>% length()\n  if (journals_num > 1) {\n    journal_names <- meta_dat$journal %>% str_split(\",\") %>% unlist()\n    journal_which <- journal_names  %>% str_length() %>% which.max()\n    meta_dat$journal <- journal_names[journal_which]\n  }\n\n  # add journal information from scimagojr\n  meta_dat$ISSN2 <- meta_dat$ISSN %>% str_replace(\".+,\", \"\") %>% str_replace_all(\"-\", \"\") %>% as.numeric() %>% as.character()\n  meta_dat$ISSN <- meta_dat$ISSN %>% str_replace_all(\"-\", \"\") %>% str_replace_all(\".+,\", \"\") %>% as.numeric() %>% as.character()\n  journal_matched <- c(match(meta_dat$ISSN[1], journals_df$journal_issn), match(meta_dat$ISSN2[1], journals_df$journal_issn), match(meta_dat$journal[1], journals_df$journal_title)) %>% na.omit %>% extract(1)\n  meta_dat <- merge(meta_dat[1,], journals_df[journal_matched,], all = TRUE)\n\n\n\n  # finalize data frame\n\n  if (is.null(vars)) {\n    meta_dat <- dplyr::select(meta_dat, doc_year, doc_author, doc_name, doc_size, author, date1, date2, title, journal, volume, issue, page, publisher, subject, type, URL, DOI, ISSN, ISSN2, reference.count, source, doi_guess, journal_sjr, journal_hindex, journal_cites_doc, journal_ref_doc, journal_country)\n  } else {\n    meta_dat <- meta_dat[,vars]\n  }\n\n  metadata <- rbind(metadata, meta_dat)\n\n\n\n\n  # RENAME FILE\n\n\n      # New Author variable\n      if(!is.null(unlist(meta_dat$author))){\n      authors <- list(NULL)\n      for(i in 1:nrow(meta_dat)){\n        test <- as.logical(!is.na(meta_dat$author[[i]][1]))\n        if(test){authors[[i]] <- meta_dat$author[[i]]$family[1]}\n\n        test2 <- as.logical(is.na(meta_dat$author[[i]][1]))\n        if(test2){authors[[i]] <- NA}\n      }\n      # paste(meta_dat$author[[i]]$family, collapse=\",\")\n      for(i in 1:length(authors)){\n        if(is.null(authors[[i]])){authors[[i]] <- NA}\n      }\n      meta_dat$author2 <- unlist(authors)\n      }else{meta_dat$author2 <- \"noauthor\"}\n\n      # New titel variable\n      meta_dat$title2 <- stringr::str_replace(substr(meta_dat$title, 1,50), \"^\\\\s\", \"\")\n      meta_dat$title2 <- stringr::str_replace(substr(meta_dat$title2, 1,50), \"[:\\\\*]\", \"\")\n      meta_dat$title2 <- stringr::str_replace(substr(meta_dat$title2, 1,50), \"\\\\s{0,3}$\", \"\")\n      meta_dat$title2 <- stringr::str_replace(substr(meta_dat$title2, 1,50), \"/\", \"_\")\n\n      # New year variableww\n      meta_dat$year <- substr(meta_dat$date1, 1,4)\n\n\n      # New title variable\n      meta_dat$new.doc_name.txt <- paste(meta_dat$author2, meta_dat$year, meta_dat$title2, sep = \" - \") %>%\n        stringr::str_replace_all(\"[?:]\", \" \") %>%\n        paste(\".txt\", sep = \"\")\n\n      meta_dat$new.doc_name.pdf <- paste(meta_dat$author2, meta_dat$year, meta_dat$title2, sep = \" - \") %>%\n        stringr::str_replace_all(\"[?:]\", \" \") %>%\n        paste(\".pdf\", sep = \"\")\n\n\n\n      # Rename .txt files\n      file.rename(from = file.path(paste(\"./\", folder, sep = \"\"), meta_dat$doc_name), to = file.path(paste(\"./\", folder, sep = \"\"), meta_dat$new.doc_name.txt))\n\n      # Rename .pdf files\n      meta_dat$doc_name_pdf <- meta_dat$doc_name %>% stringr::str_replace_all(\".txt\", \".pdf\")\n      file.rename(from = file.path(paste(\"./\", folder, sep = \"\"), meta_dat$doc_name_pdf), to = file.path(paste(\"./\", folder, sep = \"\"), meta_dat$new.doc_name.pdf))\n\n\n\n  }\n\n  # Measure time\n  time <- proc.time() - ptm\n\n  save(metadata, file = \"./metadata.RData\")\n\n\n  cat(\"\\n\\n It took around '\", as.numeric(time[3]), \"' second(s) (\", round(as.numeric(time[3])/60,2), \" minutes) to extract metadata/rename \", n.docs, \" files in the folder '\", folder, \"'.\\n\", sep = \"\")\nround(as.numeric(time[3])/60,2)\n\n}\n\n\n",
    "created" : 1463063092539.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "51083157",
    "id" : "72D19675",
    "lastKnownWriteTime" : 1463066597,
    "last_content_update" : 1463066597356,
    "path" : "C:/Users/Paul/GDrive/Packages/citations/R/get_metadata_doc_nv.R",
    "project_path" : "R/get_metadata_doc_nv.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}