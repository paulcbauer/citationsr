{
    "contents" : "#' Identifies meta information within txt documents.\n#'\n#' @param filename Input file; assumed to be txt format..\n#' @param encoding Character encoding scheme of input txt file. Default is \"utf-8\".\n#' @param lines.import Number of lines that should be imported from the input txt file. Default is 2000.\n#' @param rcrossref Use rcrossref function to identify article meta data via CrossRef API? Default is TRUE. Currently, no useful other ways of identifying metadata are implemented.\n#' @param bibtex Should reference be exported as bibtex? Works only with rcrossref = TRUE. Default is FALSE.\n#' @param vars Which variables should be returned? Specify as character vectors. By default, all available variables are returned.\n\nget_metadata_doc <- function(filename, encoding = \"UTF-8\", lines.import = 2000, rcrossref = TRUE, bibtex = FALSE, vars = NULL){\n\n  # load packages\n  require(magrittr)\n  require(stringr)\n  require(dplyr)\n\n  # open file\n  con <- file(filename, encoding = encoding)\n\n  # import text lines; lines.import specifies number of lines\n  x <- readLines(con, warn = F, n = lines.import)\n  close(con) # close connection\n\n  # remove form feed, line feed, carriage returns and empty lines from doc\n  x <- str_replace_all(x, \"[\\r\\n\\f]\" , \"\")\n  x <- str_replace_all(x, \"^[Dd]ownloaded from.+\" , \"\")\n  x <- str_replace_all(x, \"ﬁ\", \"fi\")\n  x <- x[sapply(x, nchar) > 0]\n\n  # generate empty containers\n  doc_name <- basename(filename)\n  doc_size <- file.size(filename)\n  full_line <- NA\n  doi <- NA\n  meta_source <- NA\n  doi_guess <- NA\n  meta_dat <- data.frame(author = NA, title = NA, container.title = NA, volume = NA, issue = NA, created = NA, issued = NA, page = NA, publisher = NA, subject = NA, type = NA, URL = NA, DOI = NA, ISSN = NA, link = NA, reference.count = NA, score = NA, source = NA)\n\n  # identify DOI\n  doi <- stringr::str_extract(x, '\\\\b(10[.][0-9]{4,}(?:[.][0-9]+)*/(?:(?![\"&\\'])\\\\S)+)\\\\b') # taken from http://stackoverflow.com/questions/27910/finding-a-doi-in-a-document-or-page\n  doi <- doi[!is.na(doi)]\n\n  # check if DOI contains non-ASCII characters\n  check_nonascii <- tools::showNonASCII(doi)\n  doi_nonascii <- ifelse(length(check_nonascii) > 0, TRUE, FALSE)\n\n  # if no DOI available, try fetch it from CrossRef via information from first 20 lines\n  # detect frequent lines (headers?)\n  if(length(doi)==0){\n    # significant_lines <- sort(table(x), decreasing = TRUE)[1:3] # header approach\n    # significant_lines_combined <- paste(names(frequent_lines), collapse = \" \")\n    significant_lines_combined <- paste(x[1:20], collapse = \" \") # first 20 lines approach\n    doi <- rcrossref::cr_works(query=significant_lines_combined, limit = 1)$data$DOI\n    doi_guess <- TRUE\n  }\n\n  # if DOI available, query info from CrossRef\n  if(length(doi)!=0 & doi_nonascii == FALSE){\n    # extract lines that contain identifiers of DOI\n    doi <- stringr::str_replace(doi, \"^DOI |^DOI: |DOI:|^doi |^doi: |doi:|http://dx\\\\.doi\\\\.org/\", \"\")\n    doi <- stringr::str_replace(doi, \"_supp$|\\\\.supp$\", \"\")\n    # take the first one\n    doi <- doi[1]\n    if (rcrossref == TRUE) {\n    # query crossref with DOI\n    if(bibtex == TRUE) {\n      crossref_bibtex <- rcrossref::cr_cn(dois = doi, format = \"bibtex\", style = \"apa\")\n      write(crossref_bibtex, paste0(filename, \".bib\"))\n    }\n    crossref_df <- try(rcrossref::cr_works(dois = doi) %>% .$data %>% dplyr::select(matches(\"^author$|^title$|^container.title$|^volume$|^issue$|^created$|^issued$|^page$|^publisher$|^subject$|^type$|^URL$|^DOI$|^ISSN$|^reference.count$|^score$|^source$\")))\n      if (class(crossref_df) != \"try-error\") {   # error handling if call caused an error\n        meta_dat <- crossref_df\n    }\n    meta_source <- \"CrossRef\"\n    }\n  }\n\n  # add empty variables if necessary\n  if (!(\"author\" %in% colnames(meta_dat))) { meta_dat$author <- NA }\n  if (!(\"title\" %in% colnames(meta_dat))) { meta_dat$title <- NA }\n  if (!(\"container.title\" %in% colnames(meta_dat))) { meta_dat$container.title <- NA }\n  if (!(\"volume\" %in% colnames(meta_dat))) { meta_dat$volume <- NA }\n  if (!(\"issue\" %in% colnames(meta_dat))) { meta_dat$issue <- NA }\n  if (!(\"created\" %in% colnames(meta_dat))) { meta_dat$created <- NA }\n  if (!(\"issued\" %in% colnames(meta_dat))) { meta_dat$issued <- NA }\n  if (!(\"page\" %in% colnames(meta_dat))) { meta_dat$page <- NA }\n  if (!(\"publisher\" %in% colnames(meta_dat))) { meta_dat$publisher <- NA }\n  if (!(\"subject\" %in% colnames(meta_dat))) { meta_dat$subject <- NA }\n  if (!(\"type\" %in% colnames(meta_dat))) { meta_dat$type <- NA }\n  if (!(\"URL\" %in% colnames(meta_dat))) { meta_dat$URL <- NA }\n  if (!(\"DOI\" %in% colnames(meta_dat))) { meta_dat$DOI <- NA }\n  if (!(\"ISSN\" %in% colnames(meta_dat))) { meta_dat$ISSN <- NA }\n  if (!(\"reference.count\" %in% colnames(meta_dat))) { meta_dat$reference.count <- NA }\n  if (!(\"score\" %in% colnames(meta_dat))) { meta_dat$score <- NA }\n  if (!(\"source\" %in% colnames(meta_dat))) { meta_dat$source <- NA }\n\n  # attach additional information\n  meta_dat$meta_source <- meta_source\n  meta_dat$doc_name <- doc_name\n  meta_dat$doc_size <- doc_size\n  meta_dat$doi_guess <- doi_guess\n\n  # clean variables\n  meta_dat$journal <- meta_dat$container.title\n  meta_dat$date1 <- meta_dat$created\n  meta_dat$date2 <- meta_dat$issued\n  meta_dat$doc_year <- meta_dat$doc_name %>% str_extract(\"[[:digit:]]{4}\")\n  meta_dat$doc_author <- meta_dat$doc_name %>% str_extract(\"^[[:alpha:]- .]+([[:digit:]]{4}){1}\") %>% str_replace(\"[[:digit:]]{4}\", \"\")\n\n  # clean journal variable\n  journals_num <- meta_dat$journal %>% str_split(\",\") %>% unlist() %>% length()\n  if (journals_num > 1) {\n    journal_names <- meta_dat$journal %>% str_split(\",\") %>% unlist()\n    journal_which <- journal_names  %>% str_length() %>% which.max()\n    meta_dat$journal <- journal_names[journal_which]\n  }\n\n  # add journal information from scimagojr\n  meta_dat$ISSN2 <- meta_dat$ISSN %>% str_replace(\".+,\", \"\") %>% str_replace_all(\"-\", \"\") %>% as.numeric() %>% as.character()\n  meta_dat$ISSN <- meta_dat$ISSN %>% str_replace_all(\"-\", \"\") %>% str_replace_all(\".+,\", \"\") %>% as.numeric() %>% as.character()\n  journal_matched <- c(match(meta_dat$ISSN[1], journals_df$journal_issn), match(meta_dat$ISSN2[1], journals_df$journal_issn), match(meta_dat$journal[1], journals_df$journal_title)) %>% na.omit %>% extract(1)\n  meta_dat <- merge(meta_dat[1,], journals_df[journal_matched,], all = TRUE)\n\n  # finalize data frame\n\n  if (is.null(vars)) {\n    meta_dat <- dplyr::select(meta_dat, doc_year, doc_author, doc_name, doc_size, author, date1, date2, title, journal, volume, issue, page, publisher, subject, type, URL, DOI, ISSN, ISSN2, reference.count, source, doi_guess, journal_sjr, journal_hindex, journal_cites_doc, journal_ref_doc, journal_country)\n  } else {\n    meta_dat <- meta_dat[,vars]\n  }\n\n  # return data frame\n    return(meta_dat)\n\n}\n",
    "created" : 1457664836733.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "44614772",
    "id" : "64320E30",
    "lastKnownWriteTime" : 1457664870,
    "path" : "C:/Users/paul/Google Drive/Packages/citations/R/get_metadata_doc.R",
    "project_path" : "R/get_metadata_doc.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "type" : "r_source"
}