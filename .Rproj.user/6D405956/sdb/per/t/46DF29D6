{
    "collab_server" : "",
    "contents" : "#' Generates figures with summary of analysis of citation cases\n#'\n#' @param file 'citation_data.csv' that contains data on the citation cases.\n#' @param article Name of cited article; e.g. Fearon (2003)\n#' @param output folder where figures generated by function will be stored\n#'\n#'\n#' @examples \n#' \\dontrun{\n#'  file <- \"~/Google Drive/2016_Quality_of_citations/data/Fearon 2003_citation_cases.csv\"\n#'  article <- \"Fearon and Laitin (2003)\"\n#'  output <- \"fearon_2003\"\n#'  analyze_citations(file, article, output)\n#' } \n\nanalyze_citations <- function(file, article, output){\n\n  require(ggplot2)\n  require(scales)\n  require(quanteda)\n\n  # precleaning file\n  text <- scan(file, what=\"character\", sep=\"\\n\")\n  text <- gsub('\\\\\\\\\"', \"''\", text)\n  text <- paste0(text, collapse=\"\\n\")\n  tmp <- tempfile()\n  writeLines(text, con=tmp)\n\n  # reading file and cleaning data\n  tf <- read.csv(tmp, stringsAsFactors=F, row.names=NULL, fileEncoding=\"latin1\")\n  # extracting year, deleting citations with empty years\n  tf$year <- as.numeric(gsub('.*([0-9]{4}).*', tf$document, repl='\\\\1'))\n  message(\"Warning: \", sum(is.na(tf$year)), \" citation cases with missing year will be excluded from analysis.\")\n  todelete <- which(is.na(tf$year))\n  message(\"Warning: \", sum(duplicated(tf$citation.case)), \" duplicated citation cases will be excluded from analysis.\")\n  todelete <- c(todelete, which(duplicated(tf$citation.case)))\n  message(\"Warning: \", sum(nchar(tf$citation.case)>1000), \" citation cases longer than 1000 characters will be excluded from analysis.\")\n  todelete <- unique(c(todelete, which(nchar(tf$citation.case)>1000)))\n  # exporting\n  write.csv(tf[todelete,], file=paste0(output, '/parsing-errors.csv'), row.names=FALSE)\n  tf <- tf[-todelete,] \n  message(\"A total of \", nrow(tf), \" citation cases will be included in the analysis.\")\n\n  # generating histogram with times cited within document\n  x <- table(tf$document)\n  range.x <- range(x)\n  breaks <- c(range.x[1]:range.x[2]-0.5, range.x[2]+0.5)\n  seq.x <- seq(range.x[1], range.x[2], 1)\n  f1 <- paste0(output, '/01-times-cited-within-document.pdf')\n  pdf(f1, height=4, width=6)\n  par (mar=c(3,3,2,1), mgp=c(2,.7,0), tck=-.025)\n  hist(x, xlab=\"N citation cases per document\", \n    main = paste0(\"Citation cases: \", article), xaxt=\"n\", \n    breaks=breaks, cex.main=1, ylab=\"Frequency = N documents\") \n  axis(1,seq.x)\n  dev.off()\n  message(\"File generated: \", f1)\n\n  # generating histograms for co-citations\n  tf$citation_counts <- stringr::str_count(tf$citation.case, \"(19|20)[0-9]{2}\")\n  x <- tf$citation_counts\n  # table(x)\n  range.x <- range(x)\n  breaks <- c(range.x[1]:range.x[2]-0.5, range.x[2]+0.5)\n  seq.x <- c(seq(range.x[1], range.x[2], 1))\n  f2 <- paste0(output, '/02-co-citations-in-citation-case.pdf')\n  pdf(f2, height=4, width=6)\n  par (mar=c(3,3,2,1), mgp=c(2,.7,0), tck=-.025)\n  hist(x, xlab=\"N references within citation case\", \n    main = paste0(\"Citation cases: \", article), xaxt=\"n\", breaks = breaks,  cex.main=1, ylab=\"Frequency = N citation cases\") \n  axis(1,seq.x)\n  dev.off()\n  message(\"File generated: \", f2)\n\n  # generating average number of references per citation over time\n  tf_group <- aggregate(tf$citation_counts, by=list(year=tf$year), FUN=mean, na.rm=TRUE)\n  p <- ggplot(tf_group, aes(x=as.numeric(year), y=x))\n  pq <- p + geom_point() + geom_line() + theme_minimal() +\n    theme(axis.title.x=element_blank()) + \n    scale_y_continuous(\"Average number of references in citation case\") +\n    ggtitle(paste0(\"Citation cases: \", article))\n  f3 <- paste0(output, '/03-co-citations-over-time.pdf')\n  ggsave(pq, file=f3, height=4, width=6)\n  message(\"File generated: \", f3)\n\n  # figure with positive signals\n  signal.words <- paste0(\"follow|recommend|validate|suggest|accordance|advice|demonstrate\",\n    \"|confirm|support|in line with|based\")\n  tf$signal_positive <- grepl(signal.words, tf$citation.case)\n  tf_group <- aggregate(tf$signal_positive, by=list(year=tf$year), FUN=mean, na.rm=TRUE)\n  p <- ggplot(tf_group, aes(x=as.numeric(year), y=x))\n  pq <- p + geom_point() + geom_line() + theme_minimal() +\n    theme(axis.title.x=element_blank()) + \n    scale_y_continuous(\"Proportion of citations with `positive' signal\",\n      label=percent) + ggtitle(paste0(\"Citation cases: \", article))\n  f4 <- paste0(output, '/04-citations-with-positive-signal.pdf')\n  ggsave(pq, file=f4, height=4, width=6)\n  message(\"File generated: \", f4)\n\n  # text cleaning\n  authors <- tokenize(toLower(c(tf$document, article)), removePunct=T, removeNumbers=T)\n  authors <- unique(unlist(authors))\n  # tokenizing\n  tokens <- tokenize(toLower(tf$citation.case), removePunct=T, removeNumbers=T)\n  # removing stopwords, author names, and other frequent words\n  tokens <- removeFeatures(tokens, \n    c(stopwords(\"english\"), \"other\", \"others\", \"see\", \"also\", \"u\", authors))\n  # stemming?\n  #tokens <- lapply(tokens, wordstem)\n  # creating n-grams\n  ngrams <- lapply(tokens, ngrams, 1:3)\n  # putting it all back together...\n  ngrams <- unlist(lapply(ngrams, paste, collapse=\" \"))\n  # constructing the DFM\n  cit <- corpus(ngrams)\n  docnames(cit) <- paste0(1:nrow(tf), '_', tf$document)\n  # summary(cit)\n  citmat <- dfm(cit)\n\n  # word cloud\n  f5 <- paste0(output, '/05-citations-word-cloud.pdf')\n  pdf(f5, height=4, width=4)\n  par (mar=c(0,0,0,0))\n  plot(citmat, rot.per=0, scale=c(3, .3), max.words=80)\n  dev.off()\n  message(\"File generated: \", f5)\n\n  # sentiment analysis\n  dict <- qdapDictionaries::key.pol\n  mydict <- dictionary(list(negative = dict$x[dict$y==-1],\n                          postive = dict$x[dict$y==1]))\n  myDfm <- dfm(cit, dictionary = mydict)\n  tf$neg <- as.numeric(myDfm[,1])\n  tf$pos <- as.numeric(myDfm[,2])\n  tf$score <- (tf$pos - tf$neg)\n\n  tf_group <- aggregate(tf$score, by=list(year=tf$year), FUN=mean, na.rm=TRUE)\n  p <- ggplot(tf_group, aes(x=as.numeric(year), y=x))\n  pq <- p + geom_point() + geom_line() + theme_minimal() +\n    theme(axis.title.x=element_blank()) + \n    scale_y_continuous(\"Average sentiment in citations\") + \n    ggtitle(paste0(\"Citation cases: \", article))\n  f6 <- paste0(output, '/06-sentiment-over-time.pdf')\n  ggsave(pq, file=f6, height=4, width=6)\n  message(\"File generated: \", f6) \n\n\n}\n\n",
    "created" : 1458559385567.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "226777508",
    "id" : "46DF29D6",
    "lastKnownWriteTime" : 1458636521,
    "last_content_update" : 1458636521,
    "path" : "C:/Users/pbauer/Google Drive/Packages/citations/R/analyze_citations.R",
    "project_path" : "R/analyze_citations.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}