{
    "collab_server" : "",
    "contents" : "#' Clean text files to facilitate citation case extraction.\n#'\n#' @param folder Name of folder within working directory in which the citing documents (.txt files) are located, e.g. \"Beck 1995\".\n#' @param number Number of .txt files in folder the function should be applied to. Default is \"all .txt files in folder\".\n#' @return Returns and saves text files that have been cleaned (e.g. abbreviations replaced)\n\n\nclean_text <- function(folder, number=NULL){\n\n\n  require(stringr)\n\n\n# List file names in folder (ONLY \"*processed.txt\" FILES)\n  file.names <- dir(paste(\"./\", folder, sep = \"\"), pattern = \"processed.txt\")\n\n# Generate file paths\n  file.paths <- paste(paste(\"./\", folder, \"/\", sep = \"\"), file.names, sep=\"\")\n\n# Count number of files in folder\n  n.docs <- length(file.paths)\n\n# Specify number of documents to assess by setting n.docs\n  if(!is.null(number)){n.docs <- number}\n\n\n# Loop over .txt files one by one (until document nr. \"number\" = n.docs)\n  for (i in 1:n.docs){\n    con <- file(file.paths[i], encoding = \"UTF-8\") #\n    x <- readLines(con)\n    close(con)\n    x <- paste(x, collapse = \" \")\n\n\n# Replace dots that appear in various formats\n\n    # Replace dots in abbreviations\n      x <- stringr::str_replace_all(x, \"et al\\\\.\", \"AND OTHERS\")\n      x <- stringr::str_replace_all(x, \"e\\\\.g\\\\.\", \"FOR EXAMPLE\")\n      x <- stringr::str_replace_all(x, \"etc\\\\.\", \"ET CETERA\")\n      x <- stringr::str_replace_all(x, \"cf\\\\.\", \"COMPARE\")\n      x <- stringr::str_replace_all(x, \"No\\\\.\", \"NUMBER\")\n      x <- stringr::str_replace_all(x, \"NO\\\\.\", \"NUMBER\")\n      x <- stringr::str_replace_all(x, \"fig\\\\.\", \"FIGURE\")\n      x <- stringr::str_replace_all(x, \"obs\\\\.\", \"OBSERVATIONS\")\n      x <- stringr::str_replace_all(x, \"var\\\\. \", \"VARIANCE\")\n      x <- stringr::str_replace_all(x, \"i\\\\.e\\\\.\", \"THAT IS\")\n      x <- stringr::str_replace_all(x, \"vs\\\\.\", \"VERSUS\")\n      x <- stringr::str_replace_all(x, \" p\\\\.\", \"PAGE\")\n      x <- stringr::str_replace_all(x, \"pp\\\\.\", \"PAGE\")\n      x <- stringr::str_replace_all(x, \" pp\\\\.\", \"PAGE\")\n      x <- stringr::str_replace_all(x, \"\\\\(pp\\\\.\", \"PAGE\")\n      x <- stringr::str_replace_all(x, \"apps\\\\.\", \"APPENDIX\")\n      x <- stringr::str_replace_all(x, \"app\\\\.\", \"APPENDIX\")\n      x <- stringr::str_replace_all(x, \"\\\\. \\\\. \\\\.\", \"\\\\[;;;\\\\]\")\n      x <- stringr::str_replace_all(x, \"n\\\\.d\\\\.\", \"NO DATE\")\n      x <- stringr::str_replace_all(x, \"f\\\\.n\\\\.\", \"FOOTNOTE\")\n      x <- stringr::str_replace_all(x, \"VOL\\\\.\", \"VOLUME\")\n      x <- stringr::str_replace_all(x, \"vol\\\\.\", \"VOLUME\")\n      x <- stringr::str_replace_all(x, \"esp\\\\.\", \"ESPECIALLY\")\n      x <- stringr::str_replace_all(x, \"Jr\\\\.\", \"JUNIOR\")\n      x <- stringr::str_replace_all(x, \"U\\\\.S\\\\.\", \"UNITED STATES\")\n      x <- stringr::str_replace_all(x, \"U\\\\.S\\\\.\", \"UNITED STATES\")\n      x <- stringr::str_replace_all(x, \"E\\\\.q\\\\.\", \"EQUATION\")\n      x <- stringr::str_replace_all(x, \"Eq\\\\.\", \"EQUATION\")\n      x <- stringr::str_replace_all(x, \"chs.\\\\.\", \"CHAPTERS\")\n\n      # Quotation marks\n      x <- stringr::str_replace_all(x, '\\\\\\\\\"', \"''\")\n\n\n\n      # Replace footnotes\n      detected <- unlist(stringr::str_extract_all(x, paste(\"[a-z)0-9\\\\]]\\\\.\", paste(\"(\", paste(seq(1,40), collapse=\"|\"), \")\", sep=\"\"),\"\\\\s[A-Z]\", sep=\"\")))\n      detected <- stringr::str_replace_all(detected, \"\\\\)\", \"\\\\\\\\)\")\n      if(length(detected)>0){\n        for(z in 1:length(detected)){\n          x <- stringr::str_replace_all(x, detected[z], stringr::str_replace_all(detected[z], \"\\\\.\", \"\\\\.FOOTNOTE\"))\n        }\n      }\n\n\n\n      # REPLACE DOTS IN DECIMAL NUMBER WITH \",\"\n      detected <- unlist(stringr::str_extract_all(x, \"[0-9]{1,10}\\\\.[0-9]{1,10}\"))\n      if(length(detected)>0){\n        for(z in 1:length(detected)){\n          x <- stringr::str_replace(x, detected[z], stringr::str_replace_all(detected[z], \"\\\\.\", \",\"))\n\n        }\n      }\n      # User better regex to identify numbers (see anki)\n\n\n\n\n\n\n    # Replaces dots in names in text\n      # x <- stringr::str_replace_all(x, \"G. Bingham Powell and Guy Whitten\", \"Bingham Powell and Whitten\")\n\n\n      # Get rid of em-dashes - QUESTION WHICH COMPUTER YOU USE\n        # x <- iconv(x, \"\", \"ASCII\", \"byte\")\n        # x <- stringr::str_replace_all(x, \"<c2><ad><e2><80><93>\", \"-\")\n        # x <- iconv(x, \"\", \"UTF-8\")\n\n\n    # Save cleaned text in text files\n    fileConn<-file(file.paths[i])\n    writeLines(x, fileConn, useBytes = TRUE)\n    close(fileConn)\n\n    # Counter\n    if(stringr::str_detect(as.character(i), \"[0-9]*0\")){cat(i, \".. \", sep=\"\")}\n\n    }\n\n# Message to user\n    cat(\"\\n\\n\", n.docs, \" texts/documents have been cleaned in folder '\", folder ,\"' and are now reeeeaaadddyyy to be analyzed!\\n\\n\", sep = \"\")\n\n}\n\n\n",
    "created" : 1458637325403.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4028826416",
    "id" : "933FB16D",
    "lastKnownWriteTime" : 1458637378,
    "last_content_update" : 1458637378765,
    "path" : "C:/Users/pbauer/Google Drive/Packages/citations/R/clean_text.R",
    "project_path" : "R/clean_text.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}